{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 65\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import json, os, pathlib\n",
    "import numpy as np\n",
    "\n",
    "model_path = pathlib.Path(\"data/gptlite\")\n",
    "\n",
    "# load the model from onnx file and generate text\n",
    "ort_session = ort.InferenceSession(model_path / \"model.onnx\")\n",
    "\n",
    "# load the vocabulary\n",
    "with open(model_path / \"meta.json\", \"r\") as f:\n",
    "    meta = json.load(f)\n",
    "    chars = meta['chars']\n",
    "    vocab_size = len(chars)\n",
    "    assert vocab_size == meta['vocab_size']\n",
    "    block_size = meta['block_size']\n",
    "    stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "    itos = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "    # define encode and decode functions that convert strings to arrays of tokens and vice-versa\n",
    "    encode = lambda x: [stoi[ch] for ch in x]\n",
    "    decode = lambda x: \"\".join([itos[i] for i in x])\n",
    "    vocab_size = len(stoi)\n",
    "    print(f\"Vocabulary size: {vocab_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[*([0]*253),1,2,3]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 65)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_session.run(None, {'input.1': [[*([0]*253),1,2,3]]})[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 46, 47,  1]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert(enc):\n",
    "    # pad to 256 and add extra dim\n",
    "    # return [[*([0]*(block_size-len(enc))),*enc]]\n",
    "    res =  np.pad([enc[-256:]], ((0, 0), (max(block_size - len(enc), 0), 0)), mode=\"constant\", constant_values=stoi[\"\\n\"])\n",
    "    assert res.shape == (1, block_size)\n",
    "    res = np.array(res, dtype=np.int64)\n",
    "    return res\n",
    "\n",
    "\n",
    "convert(encode(\"\\n\"* 595 + \"hi \") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_ort(start_text, max_new_tokens=100, temp=1.0, do_print=True):\n",
    "    # encode the input text\n",
    "    input_tokens_raw = encode(start_text)\n",
    "    input_tokens = convert(input_tokens_raw)\n",
    "    # input_tokens = np.pad(input_tokens, (0, block_size-len(input_tokens)), 'constant', constant_values=(0, 0))\n",
    "\n",
    "    # generate new tokens\n",
    "    if do_print:\n",
    "        print(start_text, end=\"\")\n",
    "    for i in range(max_new_tokens):\n",
    "        # get the logits for the next token\n",
    "        logits = ort_session.run(None, {\"input.1\": input_tokens})[0][0]\n",
    "        # print(logits.shape)\n",
    "        logits = logits / temp\n",
    "        probs = np.exp(logits) / np.sum(np.exp(logits))\n",
    "        next_token = np.random.choice(vocab_size, p=probs)\n",
    "        input_tokens_raw.append(next_token)\n",
    "        input_tokens = convert(input_tokens_raw)\n",
    "        if do_print:\n",
    "            print(decode([next_token]), end=\"\")\n",
    "    if do_print:\n",
    "        print(\"\\n-----------\")\n",
    "    # print(input_tokens)\n",
    "    # decode the generated tokens\n",
    "    return decode(input_tokens[0]).lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JULIET:\n",
      "What, what a well?\n",
      "\n",
      "ROMEO:\n",
      "A Mercution, that be repented\n",
      "To change thy heavier thee?\n",
      "\n",
      "PETRUCHIO:\n",
      "O, you of all of poor bosom of what stock it there,\n",
      "Being but married at the victory,\n",
      "That you'll drink me from the world, and leave the substitute\n",
      "Each their life of sights, instance can tween their\n",
      "words; they are not follow; I'll be tepostioned\n",
      "To buy and smiles as near upon our hand:\n",
      "Most woe, bei\n",
      "-----------\n",
      "here,\n",
      "Being but married at the victory,\n",
      "That you'll drink me from the world, and leave the substitute\n",
      "Each their life of sights, instance can tween their\n",
      "words; they are not follow; I'll be tepostioned\n",
      "To buy and smiles as near upon our hand:\n",
      "Most woe, bei\n"
     ]
    }
   ],
   "source": [
    "print(generate_text_ort(\"\"\"JULIET:\"\"\", max_new_tokens=400, temp=0.9))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
