{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Workshop: Generating Text using an N-gram Model\n",
    "\n",
    "## What is an N-gram Model?\n",
    "\n",
    "An $N$-gram model is a simple but powerful tool used in natural language processing (NLP) for predicting the next word in a sequence of words. It's based on the idea that the probability of a word occurring depends on the previous $N-1$ words in the sequence.\n",
    "\n",
    "## How Does it Work?\n",
    "\n",
    "Imagine we have a sentence: \"The quick brown fox jumps\". \n",
    "\n",
    "- A unigram model ($N=1$) predicts the next word based on the probability of individual words. For example, given \"The\", it might predict \"quick\" with high probability because \"quick\" often follows \"The\".\n",
    "- A bigram model ($N=2$) predicts the next word based on the probability of pairs of words. For example, given \"quick brown\", it might predict \"fox\" because \"fox\" often follows \"quick brown\".\n",
    "- An $N$-gram model generalizes this concept to predict the next word based on the probability of the previous $N-1$ words.\n",
    "\n",
    "## Model Architecture\n",
    "\n",
    "In our workshop, we'll create a simple $N$-gram model using PyTorch. Here's a simplified overview of the architecture:\n",
    "\n",
    "1. **Tokenization**: We'll convert our text data into tokens (words or characters).\n",
    "2. **Embedding**: Each token is represented as a high-dimensional vector (embedding).\n",
    "3. **Concatenation**: We concatenate the embeddings of the previous $N-1$ tokens into a single vector.\n",
    "4. **Fully-Connected Layers**: We pass the concatenated vector through fully-connected layers with activation functions like ReLU.\n",
    "5. **Output Layer**: Finally, we predict the probability distribution over the vocabulary to determine the next token.\n",
    "\n",
    "## Workshop Goals\n",
    "\n",
    "By the end of this workshop, you'll understand the basics of $N$-gram models and how they can be implemented using PyTorch. You'll also be able to train your own model and generate text based on the patterns it learns from the training data.\n",
    "\n",
    "Let's dive in and explore the world of NLP with $N$-gram models!\n",
    "\n",
    "---\n",
    "\n",
    "*Author: Shivam Gupta*\n",
    "\n",
    "*GitHub Repository: [shivamCode0/ngram](https://github.com/shivamCode0/ngram)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Setup (Run this block first)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in c:\\users\\shiva\\miniconda3\\envs\\tf\\lib\\site-packages (1.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shiva\\miniconda3\\envs\\tf\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shiva\\miniconda3\\envs\\tf\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shiva\\miniconda3\\envs\\tf\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shiva\\miniconda3\\envs\\tf\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shiva\\miniconda3\\envs\\tf\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shiva\\miniconda3\\envs\\tf\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchviz in c:\\users\\shiva\\miniconda3\\envs\\tf\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: graphviz in c:\\users\\shiva\\miniconda3\\envs\\tf\\lib\\site-packages (from torchviz) (0.20.1)\n",
      "Requirement already satisfied: torch in c:\\users\\shiva\\miniconda3\\envs\\tf\\lib\\site-packages (from torchviz) (2.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\shiva\\appdata\\roaming\\python\\python39\\site-packages (from torch->torchviz) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\shiva\\miniconda3\\envs\\tf\\lib\\site-packages (from torch->torchviz) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\shiva\\miniconda3\\envs\\tf\\lib\\site-packages (from torch->torchviz) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\shiva\\miniconda3\\envs\\tf\\lib\\site-packages (from torch->torchviz) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shiva\\miniconda3\\envs\\tf\\lib\\site-packages (from torch->torchviz) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\shiva\\miniconda3\\envs\\tf\\lib\\site-packages (from torch->torchviz) (2023.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shiva\\miniconda3\\envs\\tf\\lib\\site-packages (from jinja2->torch->torchviz) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\shiva\\miniconda3\\envs\\tf\\lib\\site-packages (from sympy->torch->torchviz) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shiva\\miniconda3\\envs\\tf\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shiva\\miniconda3\\envs\\tf\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shiva\\miniconda3\\envs\\tf\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shiva\\miniconda3\\envs\\tf\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shiva\\miniconda3\\envs\\tf\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\shiva\\miniconda3\\envs\\tf\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install torchinfo\n",
    "%pip install torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "from torchviz import make_dot\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2024-03-02 01:11:06--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8003::154, 2606:50c0:8001::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: 'data.txt'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  4% 4.74M 0s\n",
      "    50K .......... .......... .......... .......... ..........  9% 11.3M 0s\n",
      "   100K .......... .......... .......... .......... .......... 13% 14.3M 0s\n",
      "   150K .......... .......... .......... .......... .......... 18% 42.8M 0s\n",
      "   200K .......... .......... .......... .......... .......... 22% 16.4M 0s\n",
      "   250K .......... .......... .......... .......... .......... 27% 33.1M 0s\n",
      "   300K .......... .......... .......... .......... .......... 32% 78.6M 0s\n",
      "   350K .......... .......... .......... .......... .......... 36% 33.0M 0s\n",
      "   400K .......... .......... .......... .......... .......... 41% 20.6M 0s\n",
      "   450K .......... .......... .......... .......... .......... 45% 52.9M 0s\n",
      "   500K .......... .......... .......... .......... .......... 50% 44.5M 0s\n",
      "   550K .......... .......... .......... .......... .......... 55% 36.9M 0s\n",
      "   600K .......... .......... .......... .......... .......... 59% 43.9M 0s\n",
      "   650K .......... .......... .......... .......... .......... 64% 43.7M 0s\n",
      "   700K .......... .......... .......... .......... .......... 68% 40.7M 0s\n",
      "   750K .......... .......... .......... .......... .......... 73% 50.1M 0s\n",
      "   800K .......... .......... .......... .......... .......... 78% 41.7M 0s\n",
      "   850K .......... .......... .......... .......... .......... 82% 38.8M 0s\n",
      "   900K .......... .......... .......... .......... .......... 87% 40.5M 0s\n",
      "   950K .......... .......... .......... .......... .......... 91% 43.1M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 96% 46.1M 0s\n",
      "  1050K .......... .......... .......... .........            100% 40.6M=0.04s\n",
      "\n",
      "2024-03-02 01:11:07 (25.0 MB/s) - 'data.txt' saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download file to tmp/data.txt\n",
    "!wget -O data.txt https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load & Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text length: 1115394\n"
     ]
    }
   ],
   "source": [
    "with open('data.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "print('text length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️⚠️⚠️ Print first 100 characters of text ⚠️⚠️⚠️\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "# TODO: print first 100 characters of text\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PAD]\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "vocab size: 66\n"
     ]
    }
   ],
   "source": [
    "chars = [\"[PAD]\", *sorted(list(set(text)))]\n",
    "vocab_size = len(chars)\n",
    "print(\"\".join(chars))\n",
    "print(\"vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping from character to index and vice versa\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️⚠️⚠️ Verify that `encode` and `decode` work ⚠️⚠️⚠️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Hack the Treasure\n"
     ]
    }
   ],
   "source": [
    "print(decode(encode(\"Welcome to Hack the Treasure\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([19, 48, 57, 58, 59,  2, 16, 48, 59, 48, 65, 44, 53, 11,  1, 15, 44, 45,\n",
      "        54, 57, 44,  2, 62, 44,  2, 55, 57, 54, 42, 44, 44, 43,  2, 40, 53, 64,\n",
      "         2, 45, 60, 57, 59, 47, 44, 57,  7,  2, 47, 44, 40, 57,  2, 52, 44,  2,\n",
      "        58, 55, 44, 40, 50,  9,  1,  1, 14, 51, 51, 11,  1, 32, 55, 44, 40, 50,\n",
      "         7,  2, 58, 55, 44, 40, 50,  9,  1,  1, 19, 48, 57, 58, 59,  2, 16, 48,\n",
      "        59, 48, 65, 44, 53, 11,  1, 38, 54, 60], device='cuda:0')\n",
      "inputs:\n",
      "torch.Size([32, 10]) torch.int64 cuda:0\n",
      "targets:\n",
      "torch.Size([32, 10]) torch.int64 cuda:0\n"
     ]
    }
   ],
   "source": [
    "# store in tensor\n",
    "data = torch.tensor(encode(text), dtype=torch.int64, device=device)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100]) # the 100 characters we looked at earier will to the GPT look like this\n",
    "# Let's now split up the data into train and validation sets\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "block_size = 100\n",
    "train_data[:block_size+1]\n",
    "a = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "torch.manual_seed(1337)\n",
    "batch_size = 32 # how many independent sequences will we process in parallel?\n",
    "block_size = 10 # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape, xb.dtype, xb.device)\n",
    "print('targets:')\n",
    "print(yb.shape, yb.dtype, yb.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNGram(nn.Module, ABC):\n",
    "    def __init__(self, vocab_size, n):\n",
    "        super().__init__()\n",
    "        super().to(device)\n",
    "        assert n >= 3, \"n should be at least 3\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def run_calculations(self, x):\n",
    "        # to be implemented in child classes\n",
    "        pass\n",
    "    \n",
    "    # Create separate function for forward calculation\n",
    "    def forward(self, x, only_last=False):\n",
    "        assert len(x.shape) == 2, \"input shape should be (batch, time)\"\n",
    "\n",
    "        if only_last:\n",
    "            # pad time dim to at least n\n",
    "            x = x[:, -self.n :]\n",
    "            x = F.pad(x, (self.n - x.shape[1], 0), value=0)\n",
    "            B, N = x.shape\n",
    "            x = x.view(B, 1, N)\n",
    "        else:\n",
    "            new_x = torch.zeros((x.shape[0], x.shape[1], self.n), dtype=torch.int64, device=device) - 69\n",
    "            for time_index in range(x.shape[1]):\n",
    "                row = x[:, max(0, time_index - self.n + 1) : time_index + 1]\n",
    "                row = F.pad(row, (self.n - row.shape[1], 0), value=0)\n",
    "                new_x[:, time_index] = row\n",
    "            x = new_x\n",
    "\n",
    "        return self.run_calculations(x)\n",
    "\n",
    "    @abstractmethod\n",
    "    def loss_func(self, y_true, y_pred):\n",
    "        # to be implemented in child classes\n",
    "        pass\n",
    "   \n",
    "    def loss(self, logits, targets):\n",
    "        B, T, C = logits.shape\n",
    "        logits_flat = logits.view(B * T, C)\n",
    "        loss = self.loss_func(targets.view(B * T), logits_flat)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️⚠️⚠️ Define the model here. ⚠️⚠️⚠️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(BaseNGram):\n",
    "    def __init__(self, vocab_size, n):\n",
    "        super().__init__(vocab_size, n)\n",
    "        self.n = n\n",
    "        embedding_size = 50 # ⚠️ Set this to 50\n",
    "        intermediate_size = 120 # ⚠️ Set this to 120\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n",
    "        # ⚠️ Create fc layer with input size of embedding_size * n and output size of intermediate_size\n",
    "        self.fc = nn.Linear(embedding_size * n, intermediate_size)\n",
    "        # ⚠️ 20% dropout\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.final = nn.Linear(intermediate_size, vocab_size)\n",
    "    \n",
    "    def run_calculations(self, x):\n",
    "        x = self.token_embedding(x) # ⚠️ pass x through the embedding layer\n",
    "\n",
    "        # Flatten the input (already done for you)\n",
    "        x = x.view(x.shape[0], x.shape[1], -1)\n",
    "\n",
    "        # ⚠️ Pass x through the rest of the layers\n",
    "        x = self.fc(x) \n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.final(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def loss_func(self, y_true, y_pred):\n",
    "        # ⚠️ Use cross entropy loss\n",
    "        loss = F.cross_entropy(y_pred, y_true)\n",
    "        return loss\n",
    "    \n",
    "    def generate(self, x, max_len_new, temperature=1.0):\n",
    "        for _ in range(max_len_new):\n",
    "            logits = self(x, True)[:, -1] / temperature\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "            x = torch.cat([x, next_token], dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Mult-Adds\n",
      "============================================================================================================================================\n",
      "MyModel                                  [256, 10]                 [256, 1, 66]              --                        --\n",
      "├─Embedding: 1-1                         [256, 1, 7]               [256, 1, 7, 50]           3,300                     844,800\n",
      "│    └─weight                                                                                └─3,300\n",
      "├─Linear: 1-2                            [256, 1, 350]             [256, 1, 120]             42,120                    10,782,720\n",
      "│    └─weight                                                                                ├─42,000\n",
      "│    └─bias                                                                                  └─120\n",
      "├─ReLU: 1-3                              [256, 1, 120]             [256, 1, 120]             --                        --\n",
      "├─Dropout: 1-4                           [256, 1, 120]             [256, 1, 120]             --                        --\n",
      "├─Linear: 1-5                            [256, 1, 120]             [256, 1, 66]              7,986                     2,044,416\n",
      "│    └─weight                                                                                ├─7,920\n",
      "│    └─bias                                                                                  └─66\n",
      "============================================================================================================================================\n",
      "Total params: 53,406\n",
      "Trainable params: 53,406\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 13.67\n",
      "============================================================================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 1.10\n",
      "Params size (MB): 0.21\n",
      "Estimated Total Size (MB): 1.33\n",
      "============================================================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (token_embedding): Embedding(66, 50, padding_idx=0)\n",
       "  (fc): Linear(in_features=350, out_features=120, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (final): Linear(in_features=120, out_features=66, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ⚠️ Instantiate the model\n",
    "model = MyModel(vocab_size, 7)\n",
    "\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    input_data=[torch.zeros((256, 10), dtype=torch.long, device=device), True],\n",
    "    verbose=2,\n",
    "    device=device,\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"mult_adds\"],\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (token_embedding): Embedding(66, 50, padding_idx=0)\n",
      "  (fc): Linear(in_features=350, out_features=120, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (relu): ReLU()\n",
      "  (final): Linear(in_features=120, out_features=66, bias=True)\n",
      ")\n",
      "logits: torch.Size([32, 10, 66])\n",
      "loss: tensor(4.1650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "rch o' theewCQjv-eYj\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "# logits, loss = model(xb, yb)\n",
    "logits = model(xb)\n",
    "loss = model.loss(logits, yb)\n",
    "print('logits:', logits.shape)\n",
    "print('loss:', loss)\n",
    "\n",
    "print(decode(model.generate(xb, 10)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.0.2 (20221119.0110)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"376pt\" height=\"766pt\"\n",
       " viewBox=\"0.00 0.00 376.00 766.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 762)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-762 372,-762 372,4 -4,4\"/>\n",
       "<!-- 3154801393728 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>3154801393728</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"219,-31 130,-31 130,0 219,0 219,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"174.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (32, 1, 66)</text>\n",
       "</g>\n",
       "<!-- 3154841466768 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>3154841466768</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"172,-92 77,-92 77,-73 172,-73 172,-92\"/>\n",
       "<text text-anchor=\"middle\" x=\"124.5\" y=\"-80\" font-family=\"monospace\" font-size=\"10.00\">ViewBackward0</text>\n",
       "</g>\n",
       "<!-- 3154841466768&#45;&gt;3154801393728 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>3154841466768&#45;&gt;3154801393728</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M131.24,-72.73C137.66,-64.4 147.6,-51.47 156.33,-40.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"159.04,-42.34 162.36,-32.28 153.49,-38.08 159.04,-42.34\"/>\n",
       "</g>\n",
       "<!-- 3154841465520 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>3154841465520</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"225,-153 124,-153 124,-134 225,-134 225,-153\"/>\n",
       "<text text-anchor=\"middle\" x=\"174.5\" y=\"-141\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n",
       "</g>\n",
       "<!-- 3154841465520&#45;&gt;3154841466768 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>3154841465520&#45;&gt;3154841466768</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M166.91,-133.54C159.55,-124.86 148.21,-111.48 139.11,-100.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"141.95,-98.68 132.82,-93.31 136.61,-103.21 141.95,-98.68\"/>\n",
       "</g>\n",
       "<!-- 3154801982736 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>3154801982736</title>\n",
       "<polygon fill=\"#a2cd5a\" stroke=\"black\" points=\"261,-98 190,-98 190,-67 261,-67 261,-98\"/>\n",
       "<text text-anchor=\"middle\" x=\"225.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\"> (32, 66)</text>\n",
       "</g>\n",
       "<!-- 3154841465520&#45;&gt;3154801982736 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>3154841465520&#45;&gt;3154801982736</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M182.25,-133.54C188.41,-126.41 197.33,-116.09 205.46,-106.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"208.03,-109.06 211.92,-99.21 202.73,-104.48 208.03,-109.06\"/>\n",
       "</g>\n",
       "<!-- 3154841465328 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3154841465328</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-208 0,-208 0,-189 101,-189 101,-208\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-196\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 3154841465328&#45;&gt;3154841465520 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>3154841465328&#45;&gt;3154841465520</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M71.53,-188.51C91.25,-180.08 120.97,-167.38 143.41,-157.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"144.56,-161.1 152.38,-153.95 141.81,-154.66 144.56,-161.1\"/>\n",
       "</g>\n",
       "<!-- 3154802492256 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>3154802492256</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"82,-274 5,-274 5,-244 82,-244 82,-274\"/>\n",
       "<text text-anchor=\"middle\" x=\"43.5\" y=\"-262\" font-family=\"monospace\" font-size=\"10.00\">final.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"43.5\" y=\"-251\" font-family=\"monospace\" font-size=\"10.00\"> (66)</text>\n",
       "</g>\n",
       "<!-- 3154802492256&#45;&gt;3154841465328 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>3154802492256&#45;&gt;3154841465328</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M45.23,-243.54C46.1,-236.26 47.17,-227.31 48.12,-219.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"51.57,-220.02 49.28,-209.68 44.62,-219.19 51.57,-220.02\"/>\n",
       "</g>\n",
       "<!-- 3154841466336 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>3154841466336</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"222,-208 127,-208 127,-189 222,-189 222,-208\"/>\n",
       "<text text-anchor=\"middle\" x=\"174.5\" y=\"-196\" font-family=\"monospace\" font-size=\"10.00\">ViewBackward0</text>\n",
       "</g>\n",
       "<!-- 3154841466336&#45;&gt;3154841465520 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>3154841466336&#45;&gt;3154841465520</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M174.5,-188.75C174.5,-182.27 174.5,-173.16 174.5,-164.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"178,-164.96 174.5,-154.96 171,-164.96 178,-164.96\"/>\n",
       "</g>\n",
       "<!-- 3154841468256 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>3154841468256</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"249,-268.5 100,-268.5 100,-249.5 249,-249.5 249,-268.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"174.5\" y=\"-256.5\" font-family=\"monospace\" font-size=\"10.00\">NativeDropoutBackward0</text>\n",
       "</g>\n",
       "<!-- 3154841468256&#45;&gt;3154841466336 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>3154841468256&#45;&gt;3154841466336</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M174.5,-249.37C174.5,-241.5 174.5,-229.6 174.5,-219.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"178,-219.68 174.5,-209.68 171,-219.68 178,-219.68\"/>\n",
       "</g>\n",
       "<!-- 3154841468640 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>3154841468640</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"222,-334.5 127,-334.5 127,-315.5 222,-315.5 222,-334.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"174.5\" y=\"-322.5\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 3154841468640&#45;&gt;3154841468256 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>3154841468640&#45;&gt;3154841468256</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M174.5,-315.1C174.5,-306.12 174.5,-291.95 174.5,-280.22\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"178,-280.34 174.5,-270.34 171,-280.34 178,-280.34\"/>\n",
       "</g>\n",
       "<!-- 3154841467248 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>3154841467248</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"222,-395 127,-395 127,-376 222,-376 222,-395\"/>\n",
       "<text text-anchor=\"middle\" x=\"174.5\" y=\"-383\" font-family=\"monospace\" font-size=\"10.00\">ViewBackward0</text>\n",
       "</g>\n",
       "<!-- 3154841467248&#45;&gt;3154841468640 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>3154841467248&#45;&gt;3154841468640</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M174.5,-375.87C174.5,-368 174.5,-356.1 174.5,-345.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"178,-346.18 174.5,-336.18 171,-346.18 178,-346.18\"/>\n",
       "</g>\n",
       "<!-- 3154841465184 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>3154841465184</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"225,-450 124,-450 124,-431 225,-431 225,-450\"/>\n",
       "<text text-anchor=\"middle\" x=\"174.5\" y=\"-438\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n",
       "</g>\n",
       "<!-- 3154841465184&#45;&gt;3154841467248 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>3154841465184&#45;&gt;3154841467248</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M174.5,-430.75C174.5,-424.27 174.5,-415.16 174.5,-406.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"178,-406.96 174.5,-396.96 171,-406.96 178,-406.96\"/>\n",
       "</g>\n",
       "<!-- 3154841468016 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>3154841468016</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"109,-505 8,-505 8,-486 109,-486 109,-505\"/>\n",
       "<text text-anchor=\"middle\" x=\"58.5\" y=\"-493\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 3154841468016&#45;&gt;3154841465184 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>3154841468016&#45;&gt;3154841465184</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M78.18,-485.51C96.45,-477.16 123.91,-464.61 144.85,-455.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"146.1,-458.33 153.74,-450.99 143.19,-451.96 146.1,-458.33\"/>\n",
       "</g>\n",
       "<!-- 3154841378704 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>3154841378704</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"88,-571 29,-571 29,-541 88,-541 88,-571\"/>\n",
       "<text text-anchor=\"middle\" x=\"58.5\" y=\"-559\" font-family=\"monospace\" font-size=\"10.00\">fc.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"58.5\" y=\"-548\" font-family=\"monospace\" font-size=\"10.00\"> (120)</text>\n",
       "</g>\n",
       "<!-- 3154841378704&#45;&gt;3154841468016 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>3154841378704&#45;&gt;3154841468016</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M58.5,-540.54C58.5,-533.34 58.5,-524.53 58.5,-516.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"62,-516.69 58.5,-506.69 55,-516.69 62,-516.69\"/>\n",
       "</g>\n",
       "<!-- 3154841466960 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>3154841466960</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"222,-505 127,-505 127,-486 222,-486 222,-505\"/>\n",
       "<text text-anchor=\"middle\" x=\"174.5\" y=\"-493\" font-family=\"monospace\" font-size=\"10.00\">ViewBackward0</text>\n",
       "</g>\n",
       "<!-- 3154841466960&#45;&gt;3154841465184 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>3154841466960&#45;&gt;3154841465184</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M174.5,-485.75C174.5,-479.27 174.5,-470.16 174.5,-461.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"178,-461.96 174.5,-451.96 171,-461.96 178,-461.96\"/>\n",
       "</g>\n",
       "<!-- 3154841468352 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>3154841468352</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"218,-565.5 123,-565.5 123,-546.5 218,-546.5 218,-565.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"170.5\" y=\"-553.5\" font-family=\"monospace\" font-size=\"10.00\">ViewBackward0</text>\n",
       "</g>\n",
       "<!-- 3154841468352&#45;&gt;3154841466960 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>3154841468352&#45;&gt;3154841466960</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M171.09,-546.37C171.63,-538.5 172.44,-526.6 173.14,-516.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"176.61,-516.89 173.8,-506.68 169.63,-516.42 176.61,-516.89\"/>\n",
       "</g>\n",
       "<!-- 3154841466048 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>3154841466048</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"231,-631.5 106,-631.5 106,-612.5 231,-612.5 231,-631.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"168.5\" y=\"-619.5\" font-family=\"monospace\" font-size=\"10.00\">EmbeddingBackward0</text>\n",
       "</g>\n",
       "<!-- 3154841466048&#45;&gt;3154841468352 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>3154841466048&#45;&gt;3154841468352</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M168.78,-612.1C169.06,-603.12 169.5,-588.95 169.87,-577.22\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"173.36,-577.44 170.18,-567.34 166.37,-577.22 173.36,-577.44\"/>\n",
       "</g>\n",
       "<!-- 3154841467632 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>3154841467632</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"219,-692 118,-692 118,-673 219,-673 219,-692\"/>\n",
       "<text text-anchor=\"middle\" x=\"168.5\" y=\"-680\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 3154841467632&#45;&gt;3154841466048 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>3154841467632&#45;&gt;3154841466048</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M168.5,-672.87C168.5,-665 168.5,-653.1 168.5,-642.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"172,-643.18 168.5,-633.18 165,-643.18 172,-643.18\"/>\n",
       "</g>\n",
       "<!-- 3154800810000 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>3154800810000</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"243,-758 94,-758 94,-728 243,-728 243,-758\"/>\n",
       "<text text-anchor=\"middle\" x=\"168.5\" y=\"-746\" font-family=\"monospace\" font-size=\"10.00\">token_embedding.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"168.5\" y=\"-735\" font-family=\"monospace\" font-size=\"10.00\"> (66, 50)</text>\n",
       "</g>\n",
       "<!-- 3154800810000&#45;&gt;3154841467632 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>3154800810000&#45;&gt;3154841467632</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M168.5,-727.54C168.5,-720.34 168.5,-711.53 168.5,-703.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"172,-703.69 168.5,-693.69 165,-703.69 172,-703.69\"/>\n",
       "</g>\n",
       "<!-- 3154841468544 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>3154841468544</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"321,-505 244,-505 244,-486 321,-486 321,-505\"/>\n",
       "<text text-anchor=\"middle\" x=\"282.5\" y=\"-493\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n",
       "</g>\n",
       "<!-- 3154841468544&#45;&gt;3154841465184 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>3154841468544&#45;&gt;3154841465184</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M264.18,-485.51C247.32,-477.24 222.07,-464.84 202.65,-455.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"204.43,-452.29 193.91,-451.02 201.34,-458.57 204.43,-452.29\"/>\n",
       "</g>\n",
       "<!-- 3154841467104 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>3154841467104</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"340,-565.5 239,-565.5 239,-546.5 340,-546.5 340,-565.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"289.5\" y=\"-553.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 3154841467104&#45;&gt;3154841468544 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>3154841467104&#45;&gt;3154841468544</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M288.47,-546.37C287.53,-538.5 286.1,-526.6 284.88,-516.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"288.38,-516.18 283.72,-506.67 281.43,-517.02 288.38,-516.18\"/>\n",
       "</g>\n",
       "<!-- 3154805733152 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>3154805733152</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"332,-637 249,-637 249,-607 332,-607 332,-637\"/>\n",
       "<text text-anchor=\"middle\" x=\"290.5\" y=\"-625\" font-family=\"monospace\" font-size=\"10.00\">fc.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"290.5\" y=\"-614\" font-family=\"monospace\" font-size=\"10.00\"> (120, 350)</text>\n",
       "</g>\n",
       "<!-- 3154805733152&#45;&gt;3154841467104 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>3154805733152&#45;&gt;3154841467104</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M290.28,-606.8C290.14,-598.09 289.97,-586.81 289.82,-577.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"293.32,-577.3 289.66,-567.36 286.32,-577.41 293.32,-577.3\"/>\n",
       "</g>\n",
       "<!-- 3154841466384 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>3154841466384</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"336,-208 259,-208 259,-189 336,-189 336,-208\"/>\n",
       "<text text-anchor=\"middle\" x=\"297.5\" y=\"-196\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n",
       "</g>\n",
       "<!-- 3154841466384&#45;&gt;3154841465520 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>3154841466384&#45;&gt;3154841465520</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M276.63,-188.51C257.08,-180.08 227.6,-167.38 205.33,-157.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"207.02,-154.7 196.45,-153.96 204.25,-161.13 207.02,-154.7\"/>\n",
       "</g>\n",
       "<!-- 3154841468880 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>3154841468880</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"368,-268.5 267,-268.5 267,-249.5 368,-249.5 368,-268.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"317.5\" y=\"-256.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 3154841468880&#45;&gt;3154841466384 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>3154841468880&#45;&gt;3154841466384</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M314.55,-249.37C311.83,-241.42 307.7,-229.33 304.18,-219.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"307.5,-217.93 300.95,-209.6 300.88,-220.19 307.5,-217.93\"/>\n",
       "</g>\n",
       "<!-- 3154808840736 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>3154808840736</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"362,-340 273,-340 273,-310 362,-310 362,-340\"/>\n",
       "<text text-anchor=\"middle\" x=\"317.5\" y=\"-328\" font-family=\"monospace\" font-size=\"10.00\">final.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"317.5\" y=\"-317\" font-family=\"monospace\" font-size=\"10.00\"> (66, 120)</text>\n",
       "</g>\n",
       "<!-- 3154808840736&#45;&gt;3154841468880 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>3154808840736&#45;&gt;3154841468880</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M317.5,-309.8C317.5,-301.09 317.5,-289.81 317.5,-280.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"321,-280.36 317.5,-270.36 314,-280.36 321,-280.36\"/>\n",
       "</g>\n",
       "<!-- 3154801982736&#45;&gt;3154801393728 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>3154801982736&#45;&gt;3154801393728</title>\n",
       "<path fill=\"none\" stroke=\"black\" stroke-dasharray=\"1,5\" d=\"M213.93,-66.75C207.73,-58.86 199.96,-48.94 192.95,-40.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"195.89,-38.09 186.96,-32.38 190.38,-42.41 195.89,-38.09\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x2de8b3476a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot(model(xb, True), params=dict(model.named_parameters()), show_attrs=False, show_saved=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1, loss: 4.175\n",
      "step: 50, loss: 2.286\n",
      "step: 100, loss: 2.089\n",
      "step: 150, loss: 2.099\n",
      "step: 200, loss: 2.006\n",
      "step: 250, loss: 1.986\n",
      "step: 300, loss: 1.979\n",
      "step: 350, loss: 1.994\n",
      "step: 400, loss: 1.991\n",
      "step: 450, loss: 1.930\n",
      "step: 500, loss: 1.933\n",
      "step: 550, loss: 1.927\n",
      "step: 600, loss: 1.975\n",
      "step: 650, loss: 1.958\n",
      "step: 700, loss: 1.954\n",
      "step: 750, loss: 1.948\n",
      "step: 800, loss: 1.897\n",
      "step: 850, loss: 1.907\n",
      "step: 900, loss: 1.889\n",
      "step: 950, loss: 1.876\n",
      "step: 1000, loss: 1.887\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.01)\n",
    "batch_size = 256\n",
    "for step in range(1000):\n",
    "    xb, yb = get_batch('train')\n",
    "    # logits, loss = model(xb, yb)\n",
    "    logits = model(xb)\n",
    "    loss = model.loss(logits, yb)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (step + 1) % 50 == 0 or step == 0:\n",
    "        print(f'step: {step + 1}, loss: {loss.item():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(starting_text, max_length=200, temperature=0.9):\n",
    "    raw = model.generate(torch.tensor([encode(starting_text)], device=device), max_length, temperature)\n",
    "    return decode(raw[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️⚠️⚠️ Print some generated text ⚠️⚠️⚠️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "Ry breatiense alergerded\n",
      "Is acted worthan upos,\n",
      "Rome them at refere hime be most pulys: I not\n",
      "ing so anous me one the gots\n",
      "Ever this, I proving,\n",
      "Retous. Cictate you breich ther have forth seed not, \n",
      "--------------------------------------------------\n",
      "ROMEOAUNES:\n",
      "Soen thee, for thice dots, whone.\n",
      "\n",
      "GLOUCESTER:\n",
      "I foe the farty! waither,\n",
      "No, you winder foucinver an do\n",
      "zody net!\n",
      "See, or your for his that, I deavier heart I le to Pall I hoo less\n",
      "To heid the \n",
      "--------------------------------------------------\n",
      "ROMEO:\n",
      "Beshont in told I foltoo worthy noble which hask'd your to thou your too age thee I have that I am.\n",
      "\n",
      "HORMy beptice; shality!\n",
      "\n",
      "BRENNT:\n",
      "What's see.\n",
      "\n",
      "VIRGARET:\n",
      "I's and wnot with dagateld this and timel\n",
      "--------------------------------------------------\n",
      "ROMEO:\n",
      "O, to more the rean\n",
      "be mereming wher too Romeoplus fromine,\n",
      "That Kist Tive a dother benave I coped I it portionc\n",
      "And\n",
      "Beother tone!\n",
      "Dest the gover.\n",
      "\n",
      "GREANO:\n",
      "Plaff condess,\n",
      "Cisu rir to espand bright s\n",
      "--------------------------------------------------\n",
      "ROMEO:\n",
      "Would, I the brown: cuparing grack'd terince in all thus chare hapa you sovers reco:\n",
      "Geveipss\n",
      "enmienn it pers ade itive mage,\n",
      "Wist, and the potings well a chalatter,\n",
      "I'll fonles tire; weel on let on\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    # ⚠️ Insert starting text\n",
    "    print(generate_text(\"ROMEO\", 200))\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️⚠️⚠️ Experiment Time: Try different values of `temperature` and `max_len` ⚠️⚠️⚠️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can do it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the end of the tutorial part. Now, try making changes on your own and see what happens. If you need help, just ask!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
